{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D&D Dice Fraud Detection Software: Neural Network Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Make sure to switch Python / Anaconda environments to the TensorFlow one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset and Train/Validate/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(\"allDataShuffled.npz\") as file:\n",
    "    inputs = file['inputs']\n",
    "    targets=file['targets']\n",
    "    \n",
    "#loads the file from the .npz, the savez method allows us to save multiple arrays with a key we define\n",
    "#which is handy when saving objects coming from pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_FRACTION=0.8\n",
    "VALIDATE_DATA_FRACTION=0.1\n",
    "TEST_DATA_FRACTION=0.1\n",
    "Ntot=np.shape(targets)[0]\n",
    "\n",
    "#defines the fractions used for train/test/splitting. Note that these are technically model metaparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = inputs[:int(np.ceil(TRAIN_DATA_FRACTION *Ntot))]\n",
    "validate_inputs = inputs[int(np.ceil(TRAIN_DATA_FRACTION *Ntot)):int(np.ceil(VALIDATE_DATA_FRACTION*Ntot))]\n",
    "test_inputs=inputs[int(np.ceil(VALIDATE_DATA_FRACTION*Ntot)):]\n",
    "\n",
    "train_targets = targets[:int(np.ceil(TRAIN_DATA_FRACTION *Ntot))]\n",
    "validate_targets = targets[int(np.ceil(TRAIN_DATA_FRACTION *Ntot)):int(np.ceil(VALIDATE_DATA_FRACTION*Ntot))]\n",
    "test_targets=targets[int(np.ceil(VALIDATE_DATA_FRACTION*Ntot)):]\n",
    "#perform train/validate/test splitting, we assume the data is already shuffled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Neural Network and its Metaparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not, I repeat, do **NOT** mess with the Metaparameters and run the training on the same data set. Create an entirely new batch of data points with the data generation script, to avoir all possibility of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE=6\n",
    "#This is fixed by our requirements: one dice set is 6 numbers\n",
    "\n",
    "HIDDEN_LAYER_SIZE=20\n",
    "#height of each hidden layer.\n",
    "TRAIN_RATE=0.001\n",
    "#train rate can be small if using an early stopping mechanism\n",
    "OPTIMIZER=tf.keras.optimizers.Adam(learning_rate=TRAIN_RATE)\n",
    "#Adam has a momentum term that accelerates the computation but is bad for shallow minima. \n",
    "HIDDEN_LAYER_NUMBER=5\n",
    "#Number of hidden layers before the final output layer\n",
    "LAYER_SEQUENCE=[tf.keras.layers.Dense(HIDDEN_LAYER_SIZE,activation='relu') for i in range(HIDDEN_LAYER_NUMBER)]\n",
    "#Defines the hidden layer sequence based on previous parameters. \n",
    "#Activation functions are all Rectified Linear Unit, which causes fewer problems than a basic sigmoid\n",
    "#But requires normalisation, hence:\n",
    "OUTPUT_SIZE=2\n",
    "LAYER_SEQUENCE.append(tf.keras.layers.Dense(OUTPUT_SIZE, activation='softmax'))\n",
    "#Final output layer using a softmax i.e. sigmoidal output to create a unit vector\n",
    "LOSS='sparse_categorical_crossentropy'\n",
    "#the correct loss function for a one-hot encoded output layer, i.e. a categorisation problem\n",
    "\n",
    "#Note that technically we only have one output category by elimination, the following is more suited for a binary problem\n",
    "#OUTPUT_SIZE=1\n",
    "#LAYER_SEQUENCE.append(tf.keras.layers.Dense(OUTPUT_SIZE, activation='sigmoid'))\n",
    "#LOSS='binary_crossentropy'\n",
    "\n",
    "METRICS=['accuracy']\n",
    "#get feedback for the model's accuracy as training goes on\n",
    "BATCH_SIZE=100\n",
    "#to match with the size of the dataset. \n",
    "MAX_EPOCHS=200\n",
    "#to match with the train rate\n",
    "CALLBACKS= tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "#sets up an early stopping mechanism that interrupts training if loss stops decreasing.\n",
    "#patience parameter allows for some fluctuation up and down of the parameter before a full stop, useful for batch training\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnmodel=tf.keras.Sequential(LAYER_SEQUENCE)\n",
    "\n",
    "nnmodel.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=METRICS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples\n",
      "Epoch 1/200\n",
      "79200/80000 [============================>.] - ETA: 0s - loss: 0.6639 - accuracy: 0.5680"
     ]
    }
   ],
   "source": [
    "nnmodel.fit(train_inputs,train_targets,batch_size=BATCH_SIZE,epochs=MAX_EPOCHS,\n",
    "          callbacks=[CALLBACKS],\n",
    "          validation_data=(validate_inputs,validate_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
